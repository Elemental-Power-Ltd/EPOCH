"""
Thermal model fitting API endpoints.

This module provides FastAPI endpoints for creating, retrieving, and managing
thermal models of buildings. It supports:
- Fitting thermal models to historical gas consumption data
- Background processing for computationally intensive modeling tasks
- Database storage and retrieval of fitted thermal model parameters
- Integration with weather and meter data for comprehensive modeling

Thermal models characterize building heat loss properties and can be used to
simulate heating requirements under different conditions.
"""

import asyncio
import datetime
import json
import operator
import uuid

import httpx
import pandas as pd
import pydantic
from fastapi import BackgroundTasks, HTTPException
from fastapi.encoders import jsonable_encoder

from ...dependencies import DatabasePoolDep, ProcessPoolDep
from ...internal.site_manager.dataset_lists import list_elec_datasets, list_gas_datasets, list_thermal_models
from ...internal.thermal_model.fitting import fit_to_gas_usage
from ...models.core import DatasetID, DatasetTypeEnum, SiteID
from ...models.heating_load import ThermalModelResult
from ...models.thermal_model import ThermalModelRequest
from ...models.weather import WeatherRequest
from ..client_data import get_location
from ..meter_data import get_meter_data
from ..weather import get_weather
from .router import api_router


async def file_params_with_db(
    pool: DatabasePoolDep,
    site_id: str,
    task_id: pydantic.UUID4,
    results: ThermalModelResult,
    datasets: dict[DatasetTypeEnum, pydantic.UUID4],
) -> None:
    """
    Write the parameters for the thermal model to the database.

    Parameters
    ----------
    pool
        Database pool with available connections to write to the database with.
    site_id
        Foreign key, referencing the site you've done this for
    task_id
        The ID of the thermal model task, you should have generated this and handed it back to the user earlier.
    results
        The actual results for the model in the form {physical_param: float value} for the fitted parameters
    datasets
        The underlying datasets used to calculate this model, for reproducibility.

    Raises
    ------
    ValueError
        If the insertion failed for whatever reason

    Returns
    -------
    None
    """
    result = await pool.execute(
        """INSERT INTO heating.thermal_model VALUES ($1, $2, $3, $4, $5)""",
        task_id,
        datetime.datetime.now(datetime.UTC),
        site_id,
        results.model_dump_json(),
        json.dumps(jsonable_encoder(datasets)),
    )
    if result != "INSERT 0 1":
        raise ValueError("Failed to insert results into database")


async def thermal_fitting_process_wrapper(
    executor: ProcessPoolDep,
    pool: DatabasePoolDep,
    site_id: str,
    task_id: pydantic.UUID4,
    datasets: dict[DatasetTypeEnum, pydantic.UUID4],
    gas_df: pd.DataFrame,
    weather_df: pd.DataFrame,
    elec_df: pd.DataFrame | None,
    n_iter: int,
    hints: list[ThermalModelResult],
) -> None:
    """
    Monitor and join the Thermal Fitting background process.

    This should be handed a given thermal model fitting process which was already started,
    and we'll join it correctly and wait for it to be completed here.
    This should be added as a BackgroundTask so that the endpoints themselves don't wait.

    Parameters
    ----------
    executor
        A ProcessPool to run this task in
    pool
        A database pool to write to at the end
    site_id
        Foreign key, referencing the site you've done this for
    datasets
        The GasMeterData and the ElectricityMeterData you used for this fitting
    gas_df
        Gas meter dataset with start_ts, end_ts and consumption columns
    weather_df
        Weather dataset with solarradiation, temp, start_ts columns
    elec_df
        Electricity usage dataset with start_ts, end_ts and consumption columns (can be None)
    """
    loop = asyncio.get_running_loop()
    result = await loop.run_in_executor(executor, fit_to_gas_usage, gas_df, weather_df, elec_df, n_iter, hints)
    await file_params_with_db(pool, site_id, task_id, result, datasets)


@api_router.post("/get-thermal-model")
async def get_thermal_model(pool: DatabasePoolDep, dataset_id: DatasetID) -> ThermalModelResult:
    """
    Get thermal model fitted parameters from the database.

    These have been generated by `fit-thermal-model` and contain information about the size of the proxy
    building.

    Parameters
    ----------
    pool
        Connection pool for the database
    dataset_id
        The ID of the thermal model run you want to get data for

    Returns
    -------
    ThermalModelResult
        Physical parameters of the proxy building used for modelling, including the quality of this fit.
    """
    res = await pool.fetchval(
        """
        SELECT
            results
        FROM heating.thermal_model
        WHERE dataset_id = $1
        ORDER BY created_at
        LIMIT 1""",
        dataset_id.dataset_id,
    )
    if res is None:
        raise HTTPException(404, f"Could not find a thermal model for {dataset_id.dataset_id}")
    return ThermalModelResult.model_validate_json(res)


@api_router.post("/fit-thermal-model")
async def fit_thermal_model_endpoint(
    pool: DatabasePoolDep, process_pool: ProcessPoolDep, bgt: BackgroundTasks, params: ThermalModelRequest
) -> dict[str, pydantic.UUID4]:
    """
    Fit thermal model parameters via a background task.

    This will get the relevant datasets and then spin off the heavy computation into a background task.

    Parameters
    ----------
    pool
        Connection pool for the database which we'll get gas data from
    process_pool
        Pool of worker processes; we'll assign this fitting task to one of them
    bgt
        BackgroundTask collection that the fitting task will be assigned to asynchronously.
    params
        Request for the thermal model to fit,

    Returns
    -------
        The ID that this dataset will eventually get.
    """
    all_gas_datasets = await list_gas_datasets(SiteID(site_id=params.site_id), pool)
    if not all_gas_datasets:
        raise HTTPException(400, f"No gas datasets available for `{params.site_id}` to fit to.")
    latest_gas_dataset_id = max(all_gas_datasets, key=operator.attrgetter("created_at")).dataset_id

    all_elec_datasets = await list_elec_datasets(SiteID(site_id=params.site_id), pool)
    if not all_elec_datasets:
        raise HTTPException(400, f"No gas datasets available for `{params.site_id}` to fit to.")
    latest_elec_dataset_id = max(all_elec_datasets, key=operator.attrgetter("created_at")).dataset_id

    # We use the existing thermal models as probe points for the new model.
    # If we've changed the limits, watch out as some of these might end up being thrown out.
    all_thermal_metadata = await list_thermal_models(SiteID(site_id=params.site_id), pool)
    all_thermal_models = [
        await get_thermal_model(pool=pool, dataset_id=DatasetID(dataset_id=item.dataset_id)) for item in all_thermal_metadata
    ]

    async with pool.acquire() as conn, httpx.AsyncClient() as client:
        gas_meter_records = await get_meter_data(DatasetID(dataset_id=latest_gas_dataset_id), pool=pool)
        elec_meter_records = await get_meter_data(DatasetID(dataset_id=latest_elec_dataset_id), pool=pool)
        location = await get_location(SiteID(site_id=params.site_id), conn=conn)
        weather_records = await get_weather(
            weather_request=WeatherRequest(
                location=location,
                start_ts=min(item.start_ts for item in gas_meter_records),
                end_ts=max(item.end_ts for item in gas_meter_records),
            ),
            conn=conn,
            http_client=client,
        )

    elec_df = pd.DataFrame.from_records([item.model_dump() for item in elec_meter_records])
    elec_df.index = pd.to_datetime(elec_df.index)
    gas_df = pd.DataFrame.from_records([item.model_dump() for item in gas_meter_records], index="start_ts")
    gas_df["start_ts"] = gas_df.index

    # If we've got very high resolution data, it can be too noisy to fit to, so resample it into
    # weekly chunks (as those tend to align with people's schedules)
    MIN_GAS_FREQ = pd.Timedelta(days=7)
    if (gas_df["end_ts"] - gas_df["start_ts"]).mean() < MIN_GAS_FREQ:  # type: ignore
        gas_df = gas_df.resample(MIN_GAS_FREQ).sum(numeric_only=True)
        gas_df["end_ts"] = gas_df.index + MIN_GAS_FREQ
        gas_df["start_ts"] = gas_df.index
    weather_df = pd.DataFrame.from_records([item.model_dump() for item in weather_records], index="timestamp")
    weather_df["timestamp"] = weather_df.index
    task_id = uuid.uuid4()
    bgt.add_task(
        thermal_fitting_process_wrapper,
        process_pool,
        pool,
        site_id=params.site_id,
        task_id=task_id,
        datasets={
            DatasetTypeEnum.GasMeterData: latest_gas_dataset_id,
            DatasetTypeEnum.ElectricityMeterData: latest_elec_dataset_id,
        },
        gas_df=gas_df,
        weather_df=weather_df,
        elec_df=elec_df,
        n_iter=params.n_iter,
        hints=all_thermal_models,
    )
    # We just return the boring task ID here for people to get from the database later.
    # TODO (2025-04-30 MHJB): make this into a proper queue.
    return {"task_id": task_id}
